{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b7514a",
   "metadata": {},
   "source": [
    "# Computer Vision Project - Classification of Flowers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c11103",
   "metadata": {},
   "source": [
    "In this project your objective is to create a model in order to classify flowers. Thiszip file contains all relevant data. \n",
    "\n",
    "1. The data contains two folders: *train* and *test*. The *train* folder consists of 5486-images to use for training while the *test* folder contains 1351-images you can use to test your model in a **train-test-split** validation style. We have omitted another set of 1352 validation images which we will use to benchmark your final models in the last lecture. \n",
    "\n",
    "\n",
    "2. We have provided you with two label files: *train_labels.csv* and *test_labels.csv*. Each file contains the filename of the corresponding image and the class label. In total we have **102 different classes** of flowers.  You can import the label files using the `import_labels()` function provided to you in this notebook.\n",
    "\n",
    "\n",
    "3. Due to the large number of images, there is a good chance that you can not easily fit the entire training and testing data into RAM. We therefore give you an implementation of a `DataGenerator` class that can be used with keras. This class will read in the images from your hard-drive for each batch during during or testing. The class comes with some nice features that could improve your training significantly such as **image resizing**, **data augmentation** and **preprocessing**. Have a look at the code to find out how.\n",
    "\n",
    "    Initialize data generators using labels and image source directory.\n",
    "\n",
    "    `\n",
    "    datagen_train = DataGenerator('train', y_train, batch_size, input_shape, ...)\n",
    "    datagen_test = DataGenerator('test', y_test, batch_size, input_shape, ...)`\n",
    "\n",
    "    Train your model using data generators.\n",
    "\n",
    "    `model.fit(datagen_train, validation_data=datagen_test, ...)`\n",
    "    \n",
    "    \n",
    "4. Select a suitable model for classification. It is up to you to decide all model parameters, such as **number of layers**, **number and size of filter** in each layer, using **pooling** or, **image-size**, **data-augmentation**, **learning rate**, ... \n",
    "\n",
    "\n",
    "5. **Document** your progress and your intermediate results (your failures and improvements). Describe why you selected certain model and training parameters, what worked, what did not work. Store the training history (loss and accuracy) and create corresponding plots. This documentation will be part of your final presentation and will be **graded**.\n",
    "\n",
    "\n",
    "6. Feel free to explore the internet for suitable CNN models and re-use these ideas. If you use certain features we have not touched during the lecture such as Dropout, Residual Learning or Batch Normalization. Prepare a slide in your final presentation to explain in your own (basic) terms what these things to so we can all learn from your experience. **Notice:** Very large models might perform better but will be harder and slower to train. **Do not use a pre-trained model you find online!**\n",
    "\n",
    "\n",
    "7. Prepare a notebook with your model such that we can use it in the final competition. This means, store your trained model using `model.save(...)`. Your saved models can be loaded via `tf.keras.models.load_model(...)`. We will then provide you with a new folder containing images (*validation*) and a file containing labels (*validation_labels.csv*) which have the same structure. Prepare a data generator for this validation data (test it using the test data) and supply it to the \n",
    " `evaluate_model(model, datagen)` function provided to you.\n",
    " \n",
    " Your prepared notebook could look like this:\n",
    " \n",
    "    `... import stuff \n",
    "    ... code to load the stored model ...\n",
    "    y_validation = import_labels('validation_labels.csv')\n",
    "    datagen_validation = DataGenerator('validation', y_validation, batch_size, input_shape)\n",
    "    evaluate_model(model, datagen_validation)`\n",
    "\n",
    "\n",
    "8. Prepare a 15-Minute presentation of your findings and final model presentation. A rough guideline what could be interesting to your audience:\n",
    "    * Explain your models architecture (number of layers, number of total parameters, how long took it to train, ...)\n",
    "    * Compare the training history of your experimentats visually\n",
    "    * Explain your best model (why is it better)\n",
    "    * Why did you take certain decision (parameters, image size, batch size, ...)\n",
    "    * What worked, what did not work (any ideas why?)\n",
    "    * **What did you learn?**\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dde8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in label file and return a dictionary {'filename' : label}.\n",
    "#\n",
    "def import_labels(label_file):\n",
    "    labels = dict()\n",
    "\n",
    "    import csv\n",
    "    with open(label_file) as fd:\n",
    "        csvreader = csv.DictReader(fd)\n",
    "\n",
    "        for row in csvreader:\n",
    "            labels[row['filename']] = int(row['label'])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffaa6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, img_root_dir, labels_dict, batch_size, target_dim, preprocess_func=None, use_augmentation=False):\n",
    "        self._labels_dict = labels_dict\n",
    "        self._img_root_dir = img_root_dir\n",
    "        self._batch_size = batch_size\n",
    "        self._target_dim = target_dim\n",
    "        self._preprocess_func = preprocess_func\n",
    "        self._n_classes = len(set(self._labels_dict.values()))\n",
    "        self._fnames_all = list(self._labels_dict.keys())\n",
    "        self._use_augmentation = use_augmentation\n",
    "\n",
    "        if self._use_augmentation:\n",
    "            self._augmentor = image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest',\n",
    "            )\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self._fnames_all)) / self._batch_size)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self._indices = np.arange(len(self._fnames_all))\n",
    "        np.random.shuffle(self._indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self._indices[index * self._batch_size:(index+1)*self._batch_size]\n",
    "\n",
    "        fnames = [self._fnames_all[k] for k in indices]\n",
    "        X,Y = self.__load_files__(fnames)\n",
    "\n",
    "        return X,Y\n",
    "\n",
    "    def __load_files__(self, batch_filenames):\n",
    "        X = np.empty((self._batch_size, *self._target_dim, 3))\n",
    "        Y = np.empty((self._batch_size), dtype=int)\n",
    "\n",
    "        for idx, fname in enumerate(batch_filenames):\n",
    "            img_path = os.path.join(self._img_root_dir, fname)\n",
    "            img = tf.keras.utils.load_img(img_path, target_size=self._target_dim)\n",
    "            x = tf.keras.utils.img_to_array(img)\n",
    "           \n",
    "            if self._preprocess_func is not None:\n",
    "                x = self._preprocess_func(x)\n",
    "\n",
    "            X[idx,:] = x \n",
    "            Y[idx] = self._labels_dict[fname]-1\n",
    "\n",
    "        if self._use_augmentation:\n",
    "            it = self._augmentor.flow(X, batch_size=self._batch_size, shuffle=False)\n",
    "            X = it.next()\n",
    "\n",
    "            if self._preprocess_func is not None:\n",
    "                X = self._preprocess_func(X)\n",
    "\n",
    "        return X, tf.keras.utils.to_categorical(Y, num_classes=self._n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca7a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(arr):\n",
    "    scaled_data = (arr - 127.5) / 127.5\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29fb036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = DataGenerator(\"train\",import_labels(\"train_labels.csv\"),16,\n",
    "                        (224,224),prep, use_augmentation=True)\n",
    "\n",
    "data_test = DataGenerator(\"test\",import_labels(\"test_labels.csv\"),16,\n",
    "                          (224,224),prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c57b75de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plotResults(results):\n",
    "    acc = results.history['accuracy']\n",
    "    val_acc = results.history['val_accuracy']\n",
    "    loss = results.history['loss']\n",
    "    val_loss = results.history['val_loss']\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label='Training Acc')\n",
    "    plt.plot(val_acc, label='Validation Acc')\n",
    "    plt.title('Training And Validation Acc')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Training And Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef8444ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "342/342 [==============================] - 677s 2s/step - loss: 3.7999 - accuracy: 0.1873 - val_loss: 2.6056 - val_accuracy: 0.4033\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 667s 2s/step - loss: 2.0743 - accuracy: 0.5179 - val_loss: 1.2014 - val_accuracy: 0.7039\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 677s 2s/step - loss: 1.2867 - accuracy: 0.6849 - val_loss: 0.7606 - val_accuracy: 0.8095\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 650s 2s/step - loss: 0.8673 - accuracy: 0.7915 - val_loss: 0.4941 - val_accuracy: 0.8787\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 638s 2s/step - loss: 0.6398 - accuracy: 0.8480 - val_loss: 0.3098 - val_accuracy: 0.9249\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 660s 2s/step - loss: 0.4863 - accuracy: 0.8840 - val_loss: 0.2884 - val_accuracy: 0.9278\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 659s 2s/step - loss: 0.3989 - accuracy: 0.9052 - val_loss: 0.2279 - val_accuracy: 0.9375\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 625s 2s/step - loss: 0.3244 - accuracy: 0.9221 - val_loss: 0.2178 - val_accuracy: 0.9405\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 642s 2s/step - loss: 0.2635 - accuracy: 0.9346 - val_loss: 0.1948 - val_accuracy: 0.9472\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 636s 2s/step - loss: 0.2361 - accuracy: 0.9433 - val_loss: 0.1600 - val_accuracy: 0.9606\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 650s 2s/step - loss: 0.2143 - accuracy: 0.9492 - val_loss: 0.2120 - val_accuracy: 0.9435\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2423s 7s/step - loss: 0.1712 - accuracy: 0.9571 - val_loss: 0.2058 - val_accuracy: 0.9449\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 603s 2s/step - loss: 0.1646 - accuracy: 0.9600 - val_loss: 0.1638 - val_accuracy: 0.9516\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 606s 2s/step - loss: 0.1479 - accuracy: 0.9636 - val_loss: 0.1874 - val_accuracy: 0.9531\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 609s 2s/step - loss: 0.1532 - accuracy: 0.9613 - val_loss: 0.2526 - val_accuracy: 0.9338\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 623s 2s/step - loss: 0.1214 - accuracy: 0.9704 - val_loss: 0.2744 - val_accuracy: 0.9405\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 592s 2s/step - loss: 0.1234 - accuracy: 0.9720 - val_loss: 0.1711 - val_accuracy: 0.9583\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 626s 2s/step - loss: 0.1087 - accuracy: 0.9724 - val_loss: 0.2082 - val_accuracy: 0.9501\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 612s 2s/step - loss: 0.0954 - accuracy: 0.9772 - val_loss: 0.1598 - val_accuracy: 0.9531\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 638s 2s/step - loss: 0.1152 - accuracy: 0.9711 - val_loss: 0.2186 - val_accuracy: 0.9539\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 634s 2s/step - loss: 0.0964 - accuracy: 0.9766 - val_loss: 0.2228 - val_accuracy: 0.9531\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 622s 2s/step - loss: 0.1005 - accuracy: 0.9772 - val_loss: 0.1978 - val_accuracy: 0.9576\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 611s 2s/step - loss: 0.0860 - accuracy: 0.9777 - val_loss: 0.1943 - val_accuracy: 0.9494\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 553s 2s/step - loss: 0.0773 - accuracy: 0.9823 - val_loss: 0.1791 - val_accuracy: 0.9598\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 550s 2s/step - loss: 0.0791 - accuracy: 0.9814 - val_loss: 0.2059 - val_accuracy: 0.9531\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 552s 2s/step - loss: 0.0778 - accuracy: 0.9795 - val_loss: 0.2359 - val_accuracy: 0.9472\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 553s 2s/step - loss: 0.0707 - accuracy: 0.9814 - val_loss: 0.1766 - val_accuracy: 0.9576\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 551s 2s/step - loss: 0.0756 - accuracy: 0.9804 - val_loss: 0.2207 - val_accuracy: 0.9457\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 553s 2s/step - loss: 0.0680 - accuracy: 0.9834 - val_loss: 0.3148 - val_accuracy: 0.9353\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False,input_shape=(224,224,3))\n",
    "for i in base_model.layers[:-50]:\n",
    "    i.trainable = False\n",
    "model = tf.keras.models.Sequential([base_model,tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                                    tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "                                    tf.keras.layers.Dropout(0.5),\n",
    "                                    tf.keras.layers.Dense(102, activation=\"softmax\", name=\"output_layer\")])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=[\"accuracy\"])\n",
    "results = model.fit(data_train,epochs=50,validation_data = data_test,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10),\n",
    "                                                                                tf.keras.callbacks.ModelCheckpoint(\"model.h5\",\n",
    "                                                                                                                   monitor='val_accuracy',mode='max',save_best_only=True)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21b436df",
   "metadata": {},
   "source": [
    "### Flatten layer is not that important.\n",
    "### LearningRateScheduler \n",
    "### EarlyStopping\n",
    "### ModelCheckpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b139ccc1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4658a57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 29s 338ms/step - loss: 0.1600 - accuracy: 0.9606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.960565447807312"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = tf.keras.models.load_model(\"model.h5\")\n",
    "\n",
    "_,acc= saved_model.evaluate(data_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "198b55da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 102)               13158     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,435,110\n",
      "Trainable params: 2,400,998\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bdb26bb",
   "metadata": {},
   "source": [
    "# RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1826876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet import preprocess_input\n",
    "data_train = DataGenerator(\"train\",import_labels(\"train_labels.csv\"),16,\n",
    "                        (224,224),preprocess_input, use_augmentation=True)\n",
    "\n",
    "data_test = DataGenerator(\"test\",import_labels(\"test_labels.csv\"),16,\n",
    "                          (224,224),preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e9406c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "342/342 [==============================] - 925s 3s/step - loss: 3.1780 - accuracy: 0.3162 - val_loss: 2.6738 - val_accuracy: 0.4040\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 969s 3s/step - loss: 1.3101 - accuracy: 0.7016 - val_loss: 2.8740 - val_accuracy: 0.4829\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 934s 3s/step - loss: 0.7104 - accuracy: 0.8377 - val_loss: 2.3349 - val_accuracy: 0.5350\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 889s 3s/step - loss: 0.4858 - accuracy: 0.8894 - val_loss: 2.6380 - val_accuracy: 0.5499\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 700s 2s/step - loss: 0.3812 - accuracy: 0.9101 - val_loss: 2.7205 - val_accuracy: 0.5409\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 849s 2s/step - loss: 0.2933 - accuracy: 0.9379 - val_loss: 2.4423 - val_accuracy: 0.5811\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 919s 3s/step - loss: 0.2403 - accuracy: 0.9459 - val_loss: 3.5268 - val_accuracy: 0.5461\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 942s 3s/step - loss: 0.2105 - accuracy: 0.9523 - val_loss: 2.6653 - val_accuracy: 0.5513\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 836s 2s/step - loss: 0.2005 - accuracy: 0.9598 - val_loss: 1.9813 - val_accuracy: 0.6533\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 898s 3s/step - loss: 0.1810 - accuracy: 0.9614 - val_loss: 2.9844 - val_accuracy: 0.5610\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 795s 2s/step - loss: 0.1810 - accuracy: 0.9603 - val_loss: 3.1406 - val_accuracy: 0.5595\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 924s 3s/step - loss: 0.1879 - accuracy: 0.9580 - val_loss: 2.0357 - val_accuracy: 0.6429\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 878s 3s/step - loss: 0.1528 - accuracy: 0.9645 - val_loss: 1.7218 - val_accuracy: 0.6734\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 875s 3s/step - loss: 0.1363 - accuracy: 0.9691 - val_loss: 3.0578 - val_accuracy: 0.5595\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 815s 2s/step - loss: 0.0970 - accuracy: 0.9781 - val_loss: 2.0834 - val_accuracy: 0.6473\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 878s 3s/step - loss: 0.1299 - accuracy: 0.9719 - val_loss: 2.6055 - val_accuracy: 0.5908\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 929s 3s/step - loss: 0.1370 - accuracy: 0.9724 - val_loss: 2.7628 - val_accuracy: 0.5818\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 870s 3s/step - loss: 0.1399 - accuracy: 0.9735 - val_loss: 4.0610 - val_accuracy: 0.5320\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 951s 3s/step - loss: 0.1252 - accuracy: 0.9739 - val_loss: 2.2452 - val_accuracy: 0.6168\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 840s 2s/step - loss: 0.1018 - accuracy: 0.9775 - val_loss: 2.3652 - val_accuracy: 0.6071\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 795s 2s/step - loss: 0.1169 - accuracy: 0.9755 - val_loss: 2.4854 - val_accuracy: 0.6004\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 799s 2s/step - loss: 0.1044 - accuracy: 0.9783 - val_loss: 3.0295 - val_accuracy: 0.6079\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 682s 2s/step - loss: 0.0833 - accuracy: 0.9815 - val_loss: 2.0169 - val_accuracy: 0.6525\n"
     ]
    }
   ],
   "source": [
    "base_resnet = tf.keras.applications.ResNet50(False,\"imagenet\",input_shape=(224,224,3))\n",
    "\n",
    "for i in base_resnet.layers[:-75]:\n",
    "    i.trainable = False\n",
    "\n",
    "resnet = tf.keras.models.Sequential([base_resnet,tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                                    tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "                                    tf.keras.layers.Dropout(0.5),\n",
    "                                    tf.keras.layers.Dense(102, activation=\"softmax\", name=\"output_layer\")])\n",
    "\n",
    "resnet.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=[\"accuracy\"])\n",
    "results = resnet.fit(data_train,epochs=50,validation_data = data_test,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10),\n",
    "                                                                                tf.keras.callbacks.ModelCheckpoint(\"resnet_model.h5\",\n",
    "                                                                                                                   monitor='val_accuracy',mode='max',save_best_only=True)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
